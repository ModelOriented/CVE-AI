---
title: "Validation report - MIDI-to-score Conversion Model"
collection: publications
permalink: /publication/2024-01-10-MIDI
excerpt: 'This paper is about fixing template issue #693.'
date: 2024-01-10
venue: 'Explainable Machine Learning 2023/2024 course'
paperurl: 'https://modeloriented.github.io/CVE-AI/files/2023_MIDI.pdf'
citation: 'Mateusz Szymanski. (2024). &quot;Performance MIDI To Score Automatic Transcription.&quot; <i>Github: CVE-AI/ModelOriented</i>.'
tags:
  - midi
  - artifacts
---

The goal of this project is to explore and understand the latest advancements in the automatic transcription of performance MIDI streams into musical scores, speciâ€€cally within the broader scope of Audio Music Transcription (AMT). We analyze the recent paper Performance MIDI-to-score Conversion by Neural Beat Tracking (Liu et al., 2022), which comprises two main components: rhythm quantization and score generation based on a Convolutional Recurrent Neural Network (CRNN) architecture. 

We investigate the model's behavior using sequence perturbations and a LIME-like approach.

<hr/>

We were able to discover certain artifacts of the score generation models, especially when it comes to velocity contribution to hand part assignment. The time signature model is not fully robust to alterations that should not have affect the output.

Unfortunately, the proposed methods have drawbacks and are not fully justified. Current XAI methods do not work well with symbolic music data in general. Developing
more tailored and adaptable XAI methods for musical applications could contribute to improved model interpretability. One of the challenge would be to find a re

<hr/>

Link to original publiacation with a model: https://www.turing.ac.uk/sites/default/files/2022-09/midi_quantisation_paper_ismir_2022_0.pdf

